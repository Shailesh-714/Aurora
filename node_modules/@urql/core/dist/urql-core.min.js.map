{"version":3,"file":"urql-core.min.js","sources":["../src/utils/collectTypenames.ts","../src/utils/formatDocument.ts","../src/utils/operation.ts","../src/utils/index.ts","../src/exchanges/cache.ts","../src/exchanges/ssr.ts","../src/exchanges/compose.ts","../src/exchanges/map.ts","../src/exchanges/fallback.ts","../src/client.ts","../src/utils/streamUtils.ts","../src/exchanges/debug.ts","../src/exchanges/fetch.ts","../src/gql.ts","../src/exchanges/subscription.ts"],"sourcesContent":["interface EntityLike {\n  [key: string]: EntityLike | EntityLike[] | any;\n  __typename: string | null | void;\n}\n\nconst collectTypes = (obj: EntityLike | EntityLike[], types: Set<string>) => {\n  if (Array.isArray(obj)) {\n    for (let i = 0, l = obj.length; i < l; i++) {\n      collectTypes(obj[i], types);\n    }\n  } else if (typeof obj === 'object' && obj !== null) {\n    for (const key in obj) {\n      if (key === '__typename' && typeof obj[key] === 'string') {\n        types.add(obj[key] as string);\n      } else {\n        collectTypes(obj[key], types);\n      }\n    }\n  }\n\n  return types;\n};\n\n/** Finds and returns a list of `__typename` fields found in response data.\n *\n * @privateRemarks\n * This is used by `@urql/core`’s document `cacheExchange` to find typenames\n * in a given GraphQL response’s data.\n */\nexport const collectTypenames = (response: object): string[] => [\n  ...collectTypes(response as EntityLike, new Set()),\n];\n","import type {\n  FieldNode,\n  SelectionNode,\n  DefinitionNode,\n  DirectiveNode,\n} from '@0no-co/graphql.web';\nimport { Kind } from '@0no-co/graphql.web';\nimport type { KeyedDocumentNode } from './request';\nimport { keyDocument } from './request';\nimport type { FormattedNode, TypedDocumentNode } from '../types';\n\nconst formatNode = <\n  T extends SelectionNode | DefinitionNode | TypedDocumentNode<any, any>,\n>(\n  node: T\n): FormattedNode<T> => {\n  if ('definitions' in node) {\n    const definitions: FormattedNode<DefinitionNode>[] = [];\n    for (let i = 0, l = node.definitions.length; i < l; i++) {\n      const newDefinition = formatNode(node.definitions[i]);\n      definitions.push(newDefinition);\n    }\n\n    return { ...node, definitions } as FormattedNode<T>;\n  }\n\n  if ('directives' in node && node.directives && node.directives.length) {\n    const directives: DirectiveNode[] = [];\n    const _directives = {};\n    for (let i = 0, l = node.directives.length; i < l; i++) {\n      const directive = node.directives[i];\n      let name = directive.name.value;\n      if (name[0] !== '_') {\n        directives.push(directive);\n      } else {\n        name = name.slice(1);\n      }\n      _directives[name] = directive;\n    }\n    node = { ...node, directives, _directives };\n  }\n\n  if ('selectionSet' in node) {\n    const selections: FormattedNode<SelectionNode>[] = [];\n    let hasTypename = node.kind === Kind.OPERATION_DEFINITION;\n    if (node.selectionSet) {\n      for (let i = 0, l = node.selectionSet.selections.length; i < l; i++) {\n        const selection = node.selectionSet.selections[i];\n        hasTypename =\n          hasTypename ||\n          (selection.kind === Kind.FIELD &&\n            selection.name.value === '__typename' &&\n            !selection.alias);\n        const newSelection = formatNode(selection);\n        selections.push(newSelection);\n      }\n\n      if (!hasTypename) {\n        selections.push({\n          kind: Kind.FIELD,\n          name: {\n            kind: Kind.NAME,\n            value: '__typename',\n          },\n          _generated: true,\n        } as FormattedNode<FieldNode>);\n      }\n\n      return {\n        ...node,\n        selectionSet: { ...node.selectionSet, selections },\n      } as FormattedNode<T>;\n    }\n  }\n\n  return node as FormattedNode<T>;\n};\n\nconst formattedDocs: Map<number, KeyedDocumentNode> = new Map<\n  number,\n  KeyedDocumentNode\n>();\n\n/** Formats a GraphQL document to add `__typename` fields and process client-side directives.\n *\n * @param node - a {@link DocumentNode}.\n * @returns a {@link FormattedDocument}\n *\n * @remarks\n * Cache {@link Exchange | Exchanges} will require typename introspection to\n * recognize types in a GraphQL response. To retrieve these typenames,\n * this function is used to add the `__typename` fields to non-root\n * selection sets of a GraphQL document.\n *\n * Additionally, this utility will process directives, filter out client-side\n * directives starting with an `_` underscore, and place a `_directives` dictionary\n * on selection nodes.\n *\n * This utility also preserves the internally computed key of the\n * document as created by {@link createRequest} to avoid any\n * formatting from being duplicated.\n *\n * @see {@link https://spec.graphql.org/October2021/#sec-Type-Name-Introspection} for more information\n * on typename introspection via the `__typename` field.\n */\nexport const formatDocument = <T extends TypedDocumentNode<any, any>>(\n  node: T\n): FormattedNode<T> => {\n  const query = keyDocument(node);\n\n  let result = formattedDocs.get(query.__key);\n  if (!result) {\n    formattedDocs.set(\n      query.__key,\n      (result = formatNode(query) as KeyedDocumentNode)\n    );\n    // Ensure that the hash of the resulting document won't suddenly change\n    // we are marking __key as non-enumerable so when external exchanges use visit\n    // to manipulate a document we won't restore the previous query due to the __key\n    // property.\n    Object.defineProperty(result, '__key', {\n      value: query.__key,\n      enumerable: false,\n    });\n  }\n\n  return result as FormattedNode<T>;\n};\n","import type {\n  AnyVariables,\n  GraphQLRequest,\n  Operation,\n  OperationContext,\n  OperationType,\n} from '../types';\n\n/** Creates a {@link Operation} from the given parameters.\n *\n * @param kind - The {@link OperationType} of GraphQL operation, i.e. `query`, `mutation`, or `subscription`.\n * @param request - The {@link GraphQLRequest} or {@link Operation} used as a template for the new `Operation`.\n * @param context - The {@link OperationContext} `context` data for the `Operation`.\n * @returns A new {@link Operation}.\n *\n * @remarks\n * This method is both used to create new {@link Operation | Operations} as well as copy and modify existing\n * operations. While it’s not required to use this function to copy an `Operation`, it is recommended, in case\n * additional dynamic logic is added to them in the future.\n *\n * Hint: When an {@link Operation} is passed to the `request` argument, the `context` argument does not have to be\n * a complete {@link OperationContext} and will instead be combined with passed {@link Operation.context}.\n *\n * @example\n * An example of copying an existing `Operation` to modify its `context`:\n *\n * ```ts\n * makeOperation(\n *   operation.kind,\n *   operation,\n *   { requestPolicy: 'cache-first' },\n * );\n * ```\n */\nfunction makeOperation<\n  Data = any,\n  Variables extends AnyVariables = AnyVariables,\n>(\n  kind: OperationType,\n  request: GraphQLRequest<Data, Variables>,\n  context: OperationContext\n): Operation<Data, Variables>;\n\nfunction makeOperation<\n  Data = any,\n  Variables extends AnyVariables = AnyVariables,\n>(\n  kind: OperationType,\n  request: Operation<Data, Variables>,\n  context?: Partial<OperationContext>\n): Operation<Data, Variables>;\n\nfunction makeOperation(kind, request, context) {\n  return {\n    ...request,\n    kind,\n    context: request.context\n      ? {\n          ...request.context,\n          ...context,\n        }\n      : context || request.context,\n  };\n}\n\nexport { makeOperation };\n\n/** Adds additional metadata to an `Operation`'s `context.meta` property while copying it.\n * @see {@link OperationDebugMeta} for more information on the {@link OperationContext.meta} property.\n */\nexport const addMetadata = (\n  operation: Operation,\n  meta: OperationContext['meta']\n) => {\n  return makeOperation(operation.kind, operation, {\n    meta: {\n      ...operation.context.meta,\n      ...meta,\n    },\n  });\n};\n","export * from './error';\nexport * from './request';\nexport * from './result';\nexport * from './variables';\nexport * from './collectTypenames';\nexport * from './formatDocument';\nexport * from './streamUtils';\nexport * from './operation';\n\nexport const noop = () => {\n  /* noop */\n};\n","/* eslint-disable @typescript-eslint/no-use-before-define */\nimport { filter, map, merge, pipe, tap } from 'wonka';\n\nimport type { Client } from '../client';\nimport type { Exchange, Operation, OperationResult } from '../types';\n\nimport {\n  makeOperation,\n  addMetadata,\n  collectTypenames,\n  formatDocument,\n  makeResult,\n} from '../utils';\n\ntype ResultCache = Map<number, OperationResult>;\ntype OperationCache = Map<string, Set<number>>;\n\nconst shouldSkip = ({ kind }: Operation) =>\n  kind !== 'mutation' && kind !== 'query';\n\n/** Adds unique typenames to query (for invalidating cache entries) */\nexport const mapTypeNames = (operation: Operation): Operation => {\n  const query = formatDocument(operation.query);\n  if (query !== operation.query) {\n    const formattedOperation = makeOperation(operation.kind, operation);\n    formattedOperation.query = query;\n    return formattedOperation;\n  } else {\n    return operation;\n  }\n};\n\n/** Default document cache exchange.\n *\n * @remarks\n * The default document cache in `urql` avoids sending the same GraphQL request\n * multiple times by caching it using the {@link Operation.key}. It will invalidate\n * query results automatically whenever it sees a mutation responses with matching\n * `__typename`s in their responses.\n *\n * The document cache will get the introspected `__typename` fields by modifying\n * your GraphQL operation documents using the {@link formatDocument} utility.\n *\n * This automatic invalidation strategy can fail if your query or mutation don’t\n * contain matching typenames, for instance, because the query contained an\n * empty list.\n * You can manually add hints for this exchange by specifying a list of\n * {@link OperationContext.additionalTypenames} for queries and mutations that\n * should invalidate one another.\n *\n * @see {@link https://urql.dev/goto/docs/basics/document-caching} for more information on this cache.\n */\nexport const cacheExchange: Exchange = ({ forward, client, dispatchDebug }) => {\n  const resultCache: ResultCache = new Map();\n  const operationCache: OperationCache = new Map();\n\n  const isOperationCached = (operation: Operation) =>\n    operation.kind === 'query' &&\n    operation.context.requestPolicy !== 'network-only' &&\n    (operation.context.requestPolicy === 'cache-only' ||\n      resultCache.has(operation.key));\n\n  return ops$ => {\n    const cachedOps$ = pipe(\n      ops$,\n      filter(op => !shouldSkip(op) && isOperationCached(op)),\n      map(operation => {\n        const cachedResult = resultCache.get(operation.key);\n\n        dispatchDebug({\n          operation,\n          ...(cachedResult\n            ? {\n                type: 'cacheHit',\n                message: 'The result was successfully retried from the cache',\n              }\n            : {\n                type: 'cacheMiss',\n                message: 'The result could not be retrieved from the cache',\n              }),\n        });\n\n        let result: OperationResult =\n          cachedResult ||\n          makeResult(operation, {\n            data: null,\n          });\n\n        result = {\n          ...result,\n          operation: addMetadata(operation, {\n            cacheOutcome: cachedResult ? 'hit' : 'miss',\n          }),\n        };\n\n        if (operation.context.requestPolicy === 'cache-and-network') {\n          result.stale = true;\n          reexecuteOperation(client, operation);\n        }\n\n        return result;\n      })\n    );\n\n    const forwardedOps$ = pipe(\n      merge([\n        pipe(\n          ops$,\n          filter(op => !shouldSkip(op) && !isOperationCached(op)),\n          map(mapTypeNames)\n        ),\n        pipe(\n          ops$,\n          filter(op => shouldSkip(op))\n        ),\n      ]),\n      map(op => addMetadata(op, { cacheOutcome: 'miss' })),\n      filter(\n        op => op.kind !== 'query' || op.context.requestPolicy !== 'cache-only'\n      ),\n      forward,\n      tap(response => {\n        let { operation } = response;\n        if (!operation) return;\n\n        let typenames = operation.context.additionalTypenames || [];\n        // NOTE: For now, we only respect `additionalTypenames` from subscriptions to\n        // avoid unexpected breaking changes\n        // We'd expect live queries or other update mechanisms to be more suitable rather\n        // than using subscriptions as “signals” to reexecute queries. However, if they’re\n        // just used as signals, it’s intuitive to hook them up using `additionalTypenames`\n        if (response.operation.kind !== 'subscription') {\n          typenames = collectTypenames(response.data).concat(typenames);\n        }\n\n        // Invalidates the cache given a mutation's response\n        if (\n          response.operation.kind === 'mutation' ||\n          response.operation.kind === 'subscription'\n        ) {\n          const pendingOperations = new Set<number>();\n\n          dispatchDebug({\n            type: 'cacheInvalidation',\n            message: `The following typenames have been invalidated: ${typenames}`,\n            operation,\n            data: { typenames, response },\n          });\n\n          for (let i = 0; i < typenames.length; i++) {\n            const typeName = typenames[i];\n            let operations = operationCache.get(typeName);\n            if (!operations)\n              operationCache.set(typeName, (operations = new Set()));\n            for (const key of operations.values()) pendingOperations.add(key);\n            operations.clear();\n          }\n\n          for (const key of pendingOperations.values()) {\n            if (resultCache.has(key)) {\n              operation = (resultCache.get(key) as OperationResult).operation;\n              resultCache.delete(key);\n              reexecuteOperation(client, operation);\n            }\n          }\n        } else if (operation.kind === 'query' && response.data) {\n          resultCache.set(operation.key, response);\n          for (let i = 0; i < typenames.length; i++) {\n            const typeName = typenames[i];\n            let operations = operationCache.get(typeName);\n            if (!operations)\n              operationCache.set(typeName, (operations = new Set()));\n            operations.add(operation.key);\n          }\n        }\n      })\n    );\n\n    return merge([cachedOps$, forwardedOps$]);\n  };\n};\n\n/** Reexecutes an `Operation` with the `network-only` request policy.\n * @internal\n */\nexport const reexecuteOperation = (client: Client, operation: Operation) => {\n  return client.reexecuteOperation(\n    makeOperation(operation.kind, operation, {\n      requestPolicy: 'network-only',\n    })\n  );\n};\n","import type { GraphQLError } from '../utils/graphql';\nimport { pipe, filter, merge, map, tap } from 'wonka';\nimport type { Exchange, OperationResult, Operation } from '../types';\nimport { addMetadata, CombinedError } from '../utils';\nimport { reexecuteOperation, mapTypeNames } from './cache';\n\n/** A serialized version of an {@link OperationResult}.\n *\n * @remarks\n * All properties are serialized separately as JSON strings, except for the\n * {@link CombinedError} to speed up JS parsing speed, even if a result doesn’t\n * end up being used.\n *\n * @internal\n */\nexport interface SerializedResult {\n  hasNext?: boolean;\n  /** JSON-serialized version of {@link OperationResult.data}. */\n  data?: string | undefined; // JSON string of data\n  /** JSON-serialized version of {@link OperationResult.extensions}. */\n  extensions?: string | undefined;\n  /** JSON version of {@link CombinedError}. */\n  error?: {\n    graphQLErrors: Array<Partial<GraphQLError> | string>;\n    networkError?: string;\n  };\n}\n\n/** A dictionary of {@link Operation.key} keys to serializable {@link SerializedResult} objects.\n *\n * @remarks\n * It’s not recommended to modify the serialized data manually, however, multiple payloads of\n * this dictionary may safely be merged and combined.\n */\nexport interface SSRData {\n  [key: string]: SerializedResult;\n}\n\n/** Options for the `ssrExchange` allowing it to either operate on the server- or client-side. */\nexport interface SSRExchangeParams {\n  /** Indicates to the {@link SSRExchange} whether it's currently in server-side or client-side mode.\n   *\n   * @remarks\n   * Depending on this option, the {@link SSRExchange} will either capture or replay results.\n   * When `true`, it’s in client-side mode and results will be serialized. When `false`, it’ll\n   * use its deserialized data and replay results from it.\n   */\n  isClient?: boolean;\n  /** May be used on the client-side to pass the {@link SSRExchange} serialized data from the server-side.\n   *\n   * @remarks\n   * Alternatively, {@link SSRExchange.restoreData} may be called to imperatively add serialized data to\n   * the exchange.\n   *\n   * Hint: This method also works on the server-side to add to the initial serialized data, which enables\n   * you to combine multiple {@link SSRExchange} results, as needed.\n   */\n  initialState?: SSRData;\n  /** Forces a new API request to be sent in the background after replaying the deserialized result.\n   *\n   * @remarks\n   * Similarly to the `cache-and-network` {@link RequestPolicy}, this option tells the {@link SSRExchange}\n   * to send a new API request for the {@link Operation} after replaying a serialized result.\n   *\n   * Hint: This is useful when you're caching SSR results and need the client-side to update itself after\n   * rendering the initial serialized SSR results.\n   */\n  staleWhileRevalidate?: boolean;\n  /** Forces {@link OperationResult.extensions} to be serialized alongside the rest of a result.\n   *\n   * @remarks\n   * Entries in the `extension` object of a GraphQL result are often non-standard metdata, and many\n   * APIs use it for data that changes between every request. As such, the {@link SSRExchange} will\n   * not serialize this data by default, unless this flag is set.\n   */\n  includeExtensions?: boolean;\n}\n\n/** An `SSRExchange` either in server-side mode, serializing results, or client-side mode, deserializing and replaying results..\n *\n * @remarks\n * This same {@link Exchange} is used in your code both for the client-side and server-side as it’s “universal”\n * and can be put into either client-side or server-side mode using the {@link SSRExchangeParams.isClient} flag.\n *\n * In server-side mode, the `ssrExchange` will “record” results it sees from your API and provide them for you\n * to send to the client-side using the {@link SSRExchange.extractData} method.\n *\n * In client-side mode, the `ssrExchange` will use these serialized results, rehydrated either using\n * {@link SSRExchange.restoreData} or {@link SSRexchangeParams.initialState}, to replay results the\n * server-side has seen and sent before.\n *\n * Each serialized result will only be replayed once, as it’s assumed that your cache exchange will have the\n * results cached afterwards.\n */\nexport interface SSRExchange extends Exchange {\n  /** Client-side method to add serialized results to the {@link SSRExchange}.\n   * @param data - {@link SSRData},\n   */\n  restoreData(data: SSRData): void;\n  /** Server-side method to get all serialized results the {@link SSRExchange} has captured.\n   * @returns an {@link SSRData} dictionary.\n   */\n  extractData(): SSRData;\n}\n\n/** Serialize an OperationResult to plain JSON */\nconst serializeResult = (\n  result: OperationResult,\n  includeExtensions: boolean\n): SerializedResult => {\n  const serialized: SerializedResult = {\n    hasNext: result.hasNext,\n  };\n\n  if (result.data !== undefined) {\n    serialized.data = JSON.stringify(result.data);\n  }\n\n  if (includeExtensions && result.extensions !== undefined) {\n    serialized.extensions = JSON.stringify(result.extensions);\n  }\n\n  if (result.error) {\n    serialized.error = {\n      graphQLErrors: result.error.graphQLErrors.map(error => {\n        if (!error.path && !error.extensions) return error.message;\n\n        return {\n          message: error.message,\n          path: error.path,\n          extensions: error.extensions,\n        };\n      }),\n    };\n\n    if (result.error.networkError) {\n      serialized.error.networkError = '' + result.error.networkError;\n    }\n  }\n\n  return serialized;\n};\n\n/** Deserialize plain JSON to an OperationResult\n * @internal\n */\nconst deserializeResult = (\n  operation: Operation,\n  result: SerializedResult,\n  includeExtensions: boolean\n): OperationResult => ({\n  operation,\n  data: result.data ? JSON.parse(result.data) : undefined,\n  extensions:\n    includeExtensions && result.extensions\n      ? JSON.parse(result.extensions)\n      : undefined,\n  error: result.error\n    ? new CombinedError({\n        networkError: result.error.networkError\n          ? new Error(result.error.networkError)\n          : undefined,\n        graphQLErrors: result.error.graphQLErrors,\n      })\n    : undefined,\n  stale: false,\n  hasNext: !!result.hasNext,\n});\n\nconst revalidated = new Set<number>();\n\n/** Creates a server-side rendering `Exchange` that either captures responses on the server-side or replays them on the client-side.\n *\n * @param params - An {@link SSRExchangeParams} configuration object.\n * @returns the created {@link SSRExchange}\n *\n * @remarks\n * When dealing with server-side rendering, we essentially have two {@link Client | Clients} making requests,\n * the server-side client, and the client-side one. The `ssrExchange` helps implementing a tiny cache on both\n * sides that:\n *\n * - captures results on the server-side which it can serialize,\n * - replays results on the client-side that it deserialized from the server-side.\n *\n * Hint: The `ssrExchange` is basically an exchange that acts like a replacement for any fetch exchange\n * temporarily. As such, you should place it after your cache exchange but in front of any fetch exchange.\n */\nexport const ssrExchange = (params: SSRExchangeParams = {}): SSRExchange => {\n  const staleWhileRevalidate = !!params.staleWhileRevalidate;\n  const includeExtensions = !!params.includeExtensions;\n  const data: Record<string, SerializedResult | null> = {};\n\n  // On the client-side, we delete results from the cache as they're resolved\n  // this is delayed so that concurrent queries don't delete each other's data\n  const invalidateQueue: number[] = [];\n  const invalidate = (result: OperationResult) => {\n    invalidateQueue.push(result.operation.key);\n    if (invalidateQueue.length === 1) {\n      Promise.resolve().then(() => {\n        let key: number | void;\n        while ((key = invalidateQueue.shift())) {\n          data[key] = null;\n        }\n      });\n    }\n  };\n\n  // The SSR Exchange is a temporary cache that can populate results into data for suspense\n  // On the client it can be used to retrieve these temporary results from a rehydrated cache\n  const ssr: SSRExchange =\n    ({ client, forward }) =>\n    ops$ => {\n      // params.isClient tells us whether we're on the client-side\n      // By default we assume that we're on the client if suspense-mode is disabled\n      const isClient =\n        params && typeof params.isClient === 'boolean'\n          ? !!params.isClient\n          : !client.suspense;\n\n      let forwardedOps$ = pipe(\n        ops$,\n        filter(\n          operation =>\n            operation.kind === 'teardown' ||\n            !data[operation.key] ||\n            !!data[operation.key]!.hasNext ||\n            operation.context.requestPolicy === 'network-only'\n        ),\n        map(mapTypeNames),\n        forward\n      );\n\n      // NOTE: Since below we might delete the cached entry after accessing\n      // it once, cachedOps$ needs to be merged after forwardedOps$\n      let cachedOps$ = pipe(\n        ops$,\n        filter(\n          operation =>\n            operation.kind !== 'teardown' &&\n            !!data[operation.key] &&\n            operation.context.requestPolicy !== 'network-only'\n        ),\n        map(op => {\n          const serialized = data[op.key]!;\n          const cachedResult = deserializeResult(\n            op,\n            serialized,\n            includeExtensions\n          );\n\n          if (staleWhileRevalidate && !revalidated.has(op.key)) {\n            cachedResult.stale = true;\n            revalidated.add(op.key);\n            reexecuteOperation(client, op);\n          }\n\n          const result: OperationResult = {\n            ...cachedResult,\n            operation: addMetadata(op, {\n              cacheOutcome: 'hit',\n            }),\n          };\n          return result;\n        })\n      );\n\n      if (!isClient) {\n        // On the server we cache results in the cache as they're resolved\n        forwardedOps$ = pipe(\n          forwardedOps$,\n          tap((result: OperationResult) => {\n            const { operation } = result;\n            if (operation.kind !== 'mutation') {\n              const serialized = serializeResult(result, includeExtensions);\n              data[operation.key] = serialized;\n            }\n          })\n        );\n      } else {\n        // On the client we delete results from the cache as they're resolved\n        cachedOps$ = pipe(cachedOps$, tap(invalidate));\n      }\n\n      return merge([forwardedOps$, cachedOps$]);\n    };\n\n  ssr.restoreData = (restore: SSRData) => {\n    for (const key in restore) {\n      // We only restore data that hasn't been previously invalidated\n      if (data[key] !== null) {\n        data[key] = restore[key];\n      }\n    }\n  };\n\n  ssr.extractData = () => {\n    const result: SSRData = {};\n    for (const key in data) if (data[key] != null) result[key] = data[key]!;\n    return result;\n  };\n\n  if (params && params.initialState) {\n    ssr.restoreData(params.initialState);\n  }\n\n  return ssr;\n};\n","import { share } from 'wonka';\nimport type { ExchangeIO, Exchange, ExchangeInput } from '../types';\n\n/** Composes an array of Exchanges into a single one.\n *\n * @param exchanges - An array of {@link Exchange | Exchanges}.\n * @returns - A composed {@link Exchange}.\n *\n * @remarks\n * `composeExchanges` returns an {@link Exchange} that when instantiated\n * composes the array of passed `Exchange`s into one, calling them from\n * right to left, with the prior `Exchange`’s {@link ExchangeIO} function\n * as the {@link ExchangeInput.forward} input.\n *\n * This simply merges all exchanges into one and is used by the {@link Client}